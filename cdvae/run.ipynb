{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Optional, Sequence\n",
    "from pathlib import Path\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from cdvae.common.utils import PROJECT_ROOT\n",
    "from cdvae.common.data_utils import get_scaler_from_data_list\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import hydra\n",
    "import numpy as np\n",
    "import torch\n",
    "import omegaconf\n",
    "import pytorch_lightning as pl\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning import seed_everything, Callback\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from cdvae.common.utils import log_hyperparameters, PROJECT_ROOT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def worker_init_fn(id: int):\n",
    "    \"\"\"\n",
    "    DataLoaders workers init function.\n",
    "\n",
    "    Initialize the numpy.random seed correctly for each worker, so that\n",
    "    random augmentations between workers and/or epochs are not identical.\n",
    "\n",
    "    If a global seed is set, the augmentations are deterministic.\n",
    "\n",
    "    https://pytorch.org/docs/stable/notes/randomness.html#dataloader\n",
    "    \"\"\"\n",
    "    uint64_seed = torch.initial_seed()\n",
    "    ss = np.random.SeedSequence([uint64_seed])\n",
    "    # More than 128 bits (4 32-bit words) would be overkill.\n",
    "    np.random.seed(ss.generate_state(4))\n",
    "    random.seed(uint64_seed)\n",
    "\n",
    "\n",
    "class CrystDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        datasets: DictConfig,\n",
    "        num_workers: DictConfig,\n",
    "        batch_size: DictConfig,\n",
    "        scaler_path=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.datasets = datasets\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_dataset: Optional[Dataset] = None\n",
    "        self.val_datasets: Optional[Sequence[Dataset]] = None\n",
    "        self.test_datasets: Optional[Sequence[Dataset]] = None\n",
    "\n",
    "        self.get_scaler(scaler_path)\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # download only\n",
    "        pass\n",
    "\n",
    "    def get_scaler(self, scaler_path):\n",
    "        # Load once to compute property scaler\n",
    "        if scaler_path is None:\n",
    "            train_dataset = hydra.utils.instantiate(self.datasets.train)\n",
    "            self.lattice_scaler = get_scaler_from_data_list(\n",
    "                train_dataset.cached_data,\n",
    "                key='scaled_lattice')\n",
    "            self.scaler = get_scaler_from_data_list(\n",
    "                train_dataset.cached_data,\n",
    "                key=train_dataset.prop)\n",
    "        else:\n",
    "            self.lattice_scaler = torch.load(\n",
    "                Path(scaler_path) / 'lattice_scaler.pt')\n",
    "            self.scaler = torch.load(Path(scaler_path) / 'prop_scaler.pt')\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        construct datasets and assign data scalers.\n",
    "        \"\"\"\n",
    "        if stage is None or stage == \"fit\":\n",
    "            self.train_dataset = hydra.utils.instantiate(self.datasets.train)\n",
    "            self.val_datasets = [\n",
    "                hydra.utils.instantiate(dataset_cfg)\n",
    "                for dataset_cfg in self.datasets.val\n",
    "            ]\n",
    "\n",
    "            self.train_dataset.lattice_scaler = self.lattice_scaler\n",
    "            self.train_dataset.scaler = self.scaler\n",
    "            for val_dataset in self.val_datasets:\n",
    "                val_dataset.lattice_scaler = self.lattice_scaler\n",
    "                val_dataset.scaler = self.scaler\n",
    "\n",
    "        if stage is None or stage == \"test\":\n",
    "            self.test_datasets = [\n",
    "                hydra.utils.instantiate(dataset_cfg)\n",
    "                for dataset_cfg in self.datasets.test\n",
    "            ]\n",
    "            for test_dataset in self.test_datasets:\n",
    "                test_dataset.lattice_scaler = self.lattice_scaler\n",
    "                test_dataset.scaler = self.scaler\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            shuffle=True,\n",
    "            batch_size=self.batch_size.train,\n",
    "            num_workers=self.num_workers.train,\n",
    "            worker_init_fn=worker_init_fn,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> Sequence[DataLoader]:\n",
    "        return [\n",
    "            DataLoader(\n",
    "                dataset,\n",
    "                shuffle=False,\n",
    "                batch_size=self.batch_size.val,\n",
    "                num_workers=self.num_workers.val,\n",
    "                worker_init_fn=worker_init_fn,\n",
    "            )\n",
    "            for dataset in self.val_datasets\n",
    "        ]\n",
    "\n",
    "    def test_dataloader(self) -> Sequence[DataLoader]:\n",
    "        return [\n",
    "            DataLoader(\n",
    "                dataset,\n",
    "                shuffle=False,\n",
    "                batch_size=self.batch_size.test,\n",
    "                num_workers=self.num_workers.test,\n",
    "                worker_init_fn=worker_init_fn,\n",
    "            )\n",
    "            for dataset in self.test_datasets\n",
    "        ]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"{self.__class__.__name__}(\"\n",
    "            f\"{self.datasets=}, \"\n",
    "            f\"{self.num_workers=}, \"\n",
    "            f\"{self.batch_size=})\"\n",
    "        )\n",
    "\n",
    "def build_callbacks(cfg: DictConfig) -> List[Callback]:\n",
    "    callbacks: List[Callback] = []\n",
    "\n",
    "    if \"lr_monitor\" in cfg.logging:\n",
    "        hydra.utils.log.info(\"Adding callback <LearningRateMonitor>\")\n",
    "        callbacks.append(\n",
    "            LearningRateMonitor(\n",
    "                logging_interval=cfg.logging.lr_monitor.logging_interval,\n",
    "                log_momentum=cfg.logging.lr_monitor.log_momentum,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if \"early_stopping\" in cfg.train:\n",
    "        hydra.utils.log.info(\"Adding callback <EarlyStopping>\")\n",
    "        callbacks.append(\n",
    "            EarlyStopping(\n",
    "                monitor=cfg.train.monitor_metric,\n",
    "                mode=cfg.train.monitor_metric_mode,\n",
    "                patience=cfg.train.early_stopping.patience,\n",
    "                verbose=cfg.train.early_stopping.verbose,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if \"model_checkpoints\" in cfg.train:\n",
    "        hydra.utils.log.info(\"Adding callback <ModelCheckpoint>\")\n",
    "        callbacks.append(\n",
    "            ModelCheckpoint(\n",
    "                dirpath=Path('C:\\\\Users\\\\TOSHIBA\\\\Desktop\\\\work\\hydra\\\\singlerun\\\\2024-03-28\\\\test'),\n",
    "                monitor=cfg.train.monitor_metric,\n",
    "                mode=cfg.train.monitor_metric_mode,\n",
    "                save_top_k=cfg.train.model_checkpoints.save_top_k,\n",
    "                verbose=cfg.train.model_checkpoints.verbose,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\hydra\\_internal\\defaults_list.py:251: UserWarning: In 'default.yaml': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'root_path': '${oc.env:PROJECT_ROOT}/data/perov_5', 'prop': 'heat_ref', 'num_targets': 1, 'niggli': True, 'primitive': False, 'graph_method': 'crystalnn', 'lattice_scale_method': 'scale_length', 'preprocess_workers': 30, 'readout': 'mean', 'max_atoms': 20, 'otf_graph': False, 'eval_model_name': 'perovskite', 'train_max_epochs': 3000, 'early_stopping_patience': 100000, 'teacher_forcing_max_epoch': 1500, 'datamodule': {'_target_': 'cdvae.pl_data.datamodule.CrystDataModule', 'datasets': {'train': {'_target_': 'cdvae.pl_data.dataset.CrystDataset', 'name': 'Formation energy train', 'path': '${data.root_path}/train.csv', 'prop': '${data.prop}', 'niggli': '${data.niggli}', 'primitive': '${data.primitive}', 'graph_method': '${data.graph_method}', 'lattice_scale_method': '${data.lattice_scale_method}', 'preprocess_workers': '${data.preprocess_workers}'}, 'val': [{'_target_': 'cdvae.pl_data.dataset.CrystDataset', 'name': 'Formation energy val', 'path': '${data.root_path}/val.csv', 'prop': '${data.prop}', 'niggli': '${data.niggli}', 'primitive': '${data.primitive}', 'graph_method': '${data.graph_method}', 'lattice_scale_method': '${data.lattice_scale_method}', 'preprocess_workers': '${data.preprocess_workers}'}], 'test': [{'_target_': 'cdvae.pl_data.dataset.CrystDataset', 'name': 'Formation energy test', 'path': '${data.root_path}/test.csv', 'prop': '${data.prop}', 'niggli': '${data.niggli}', 'primitive': '${data.primitive}', 'graph_method': '${data.graph_method}', 'lattice_scale_method': '${data.lattice_scale_method}', 'preprocess_workers': '${data.preprocess_workers}'}]}, 'num_workers': {'train': 0, 'val': 0, 'test': 0}, 'batch_size': {'train': 32, 'val': 16, 'test': 16}}}, 'logging': {'val_check_interval': 1, 'progress_bar_refresh_rate': 20, 'wandb': {'name': '${expname}', 'project': 'crystal_generation_mit', 'entity': None, 'log_model': True, 'mode': 'online', 'group': '${expname}'}, 'wandb_watch': {'log': 'all', 'log_freq': 500}, 'lr_monitor': {'logging_interval': 'step', 'log_momentum': False}}, 'model': {'encoder': {'_target_': 'cdvae.pl_modules.gnn.DimeNetPlusPlusWrap', 'num_targets': '${data.num_targets}', 'hidden_channels': 128, 'num_blocks': 4, 'int_emb_size': 64, 'basis_emb_size': 8, 'out_emb_channels': 256, 'num_spherical': 7, 'num_radial': 6, 'otf_graph': '${data.otf_graph}', 'cutoff': 7.0, 'max_num_neighbors': 20, 'envelope_exponent': 5, 'num_before_skip': 1, 'num_after_skip': 2, 'num_output_layers': 3, 'readout': '${data.readout}'}, 'decoder': {'_target_': 'cdvae.pl_modules.decoder.GemNetTDecoder', 'hidden_dim': 128, 'latent_dim': '${model.latent_dim}', 'max_neighbors': '${model.max_neighbors}', 'radius': '${model.radius}', 'scale_file': '${oc.env:PROJECT_ROOT}/cdvae/pl_modules/gemnet/gemnet-dT.json'}, '_target_': 'cdvae.pl_modules.model.CDVAE', 'hidden_dim': 256, 'latent_dim': 256, 'fc_num_layers': 1, 'max_atoms': '${data.max_atoms}', 'cost_natom': 1.0, 'cost_coord': 10.0, 'cost_type': 1.0, 'cost_lattice': 10.0, 'cost_composition': 1.0, 'cost_edge': 10.0, 'cost_property': 1.0, 'beta': 0.01, 'teacher_forcing_lattice': True, 'teacher_forcing_max_epoch': '${data.teacher_forcing_max_epoch}', 'max_neighbors': 20, 'radius': 7.0, 'sigma_begin': 10.0, 'sigma_end': 0.01, 'type_sigma_begin': 5.0, 'type_sigma_end': 0.01, 'num_noise_level': 50, 'predict_property': False}, 'optim': {'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0}, 'use_lr_scheduler': True, 'lr_scheduler': {'_target_': 'torch.optim.lr_scheduler.ReduceLROnPlateau', 'factor': 0.6, 'patience': 30, 'min_lr': 0.0001}}, 'train': {'deterministic': False, 'random_seed': 42, 'pl_trainer': {'fast_dev_run': False, 'gpus': 1, 'precision': 32, 'max_epochs': '${data.train_max_epochs}', 'accumulate_grad_batches': 1, 'num_sanity_val_steps': 2, 'gradient_clip_val': 0.5, 'gradient_clip_algorithm': 'value', 'profiler': 'simple'}, 'monitor_metric': 'val_loss', 'monitor_metric_mode': 'min', 'early_stopping': {'patience': '${data.early_stopping_patience}', 'verbose': False}, 'model_checkpoints': {'save_top_k': 1, 'verbose': False}}, 'expname': 'test', 'core': {'version': '0.0.1', 'tags': ['${now:%Y-%m-%d}']}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "with initialize(version_base=None, config_path=\"..\\conf\"):\n",
    "    cfg = compose(config_name=\"default.yaml\")\n",
    "    print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\pl_data\\datamodule.py:142: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n",
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\pl_data\\dataset.py:126: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a2628ab1ae4eecafb49fb98f9c54a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\common\\data_utils.py:644: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  targets = torch.tensor([d[key] for d in data_list])\n",
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\common\\data_utils.py:612: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "datamodule: pl.LightningDataModule = hydra.utils.instantiate(\n",
    "        cfg.data.datamodule, _recursive_=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\pl_modules\\model.py:635: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  @hydra.main(config_path=str(PROJECT_ROOT / \"conf\"), config_name=\"default\")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model\n",
    "hydra.utils.log.info(f\"Instantiating <{cfg.model._target_}>\")\n",
    "model: pl.LightningModule = hydra.utils.instantiate(\n",
    "    cfg.model,\n",
    "    optim=cfg.optim,\n",
    "    data=cfg.data,\n",
    "    logging=cfg.logging,\n",
    "    _recursive_=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lattice_scaler = datamodule.lattice_scaler.copy()\n",
    "model.scaler = datamodule.scaler.copy()\n",
    "torch.save(datamodule.lattice_scaler,  'C:\\\\Users\\\\TOSHIBA\\\\Desktop\\\\work\\hydra\\\\singlerun\\\\2024-03-28\\\\test\\\\lattice_scaler.pt')\n",
    "torch.save(datamodule.scaler, 'C:\\\\Users\\\\TOSHIBA\\\\Desktop\\\\work\\hydra\\\\singlerun\\\\2024-03-28\\\\test\\\\prop_scaler.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TOSHIBA\\Desktop\\work\\hydra\\singlerun\\2024-03-28\\test\\epoch=84-step=340.ckpt\n"
     ]
    }
   ],
   "source": [
    "hydra_dir = Path('C:\\\\Users\\\\TOSHIBA\\\\Desktop\\\\work\\hydra\\\\singlerun\\\\2024-03-28\\\\test')\n",
    "# Load checkpoint (if exist)\n",
    "ckpts = list(hydra_dir.glob('*.ckpt'))\n",
    "if len(ckpts) > 0:\n",
    "    ckpt_epochs = np.array([int(ckpt.parts[-1].split('-')[0].split('=')[1]) for ckpt in ckpts])\n",
    "    ckpt = str(ckpts[ckpt_epochs.argsort()[-1]])\n",
    "    hydra.utils.log.info(f\"found checkpoint: {ckpt}\")\n",
    "else:\n",
    "    ckpt = None\n",
    "\n",
    "print(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fast_dev_run': False, 'gpus': 1, 'precision': 32, 'max_epochs': '${data.train_max_epochs}', 'accumulate_grad_batches': 1, 'num_sanity_val_steps': 2, 'gradient_clip_val': 0.5, 'gradient_clip_algorithm': 'value', 'profiler': 'simple'}\n"
     ]
    }
   ],
   "source": [
    "print(cfg.train.pl_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "hydra.utils.log.info(\"Instantiating the Trainer\")\n",
    "callbacks: List[Callback] = build_callbacks(cfg=cfg)\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=hydra_dir,\n",
    "    logger=None,\n",
    "    callbacks=callbacks,\n",
    "    deterministic=cfg.train.deterministic,\n",
    "    check_val_every_n_epoch=cfg.logging.val_check_interval,\n",
    "    enable_progress_bar=True,\n",
    "    profiler = 'simple',\n",
    "    precision=32,\n",
    "    max_epochs= 100,\n",
    "    accumulate_grad_batches=1,\n",
    "    num_sanity_val_steps=2,\n",
    "    gradient_clip_val=0.5,\n",
    "    gradient_clip_algorithm='value'\n",
    ")\n",
    "log_hyperparameters(trainer=trainer, model=model, cfg=cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799e5c90ca3f4a95837e1f37b4fb206d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6073411c3a141feadb999f87ebd8ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:653: Checkpoint directory C:\\Users\\TOSHIBA\\Desktop\\work\\hydra\\singlerun\\2024-03-28\\test exists and is not empty.\n",
      "\n",
      "  | Name           | Type                | Params\n",
      "-------------------------------------------------------\n",
      "0 | encoder        | DimeNetPlusPlusWrap | 2.2 M \n",
      "1 | decoder        | GemNetTDecoder      | 2.3 M \n",
      "2 | fc_mu          | Linear              | 65.8 K\n",
      "3 | fc_var         | Linear              | 65.8 K\n",
      "4 | fc_num_atoms   | Sequential          | 71.2 K\n",
      "5 | fc_lattice     | Sequential          | 67.3 K\n",
      "6 | fc_composition | Sequential          | 91.5 K\n",
      "  | other params   | n/a                 | 100   \n",
      "-------------------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "117       Non-trainable params\n",
      "4.9 M     Total params\n",
      "19.682    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfce5d3b2b84bc0a77047e4146aa39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\common\\data_utils.py:622: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float)\n",
      "c:\\users\\toshiba\\desktop\\work\\cdvae\\cdvae\\common\\data_utils.py:618: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = torch.tensor(X, dtype=torch.float)\n",
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\TOSHIBA\\.conda\\envs\\cdvae\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                               \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                \t|  -              \t|  38178          \t|  5032.4         \t|  100 %          \t|\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                   \t|  12.249         \t|  100            \t|  1224.9         \t|  24.34          \t|\n",
      "|  run_training_batch                                                                                                                                                   \t|  1.9782         \t|  400            \t|  791.27         \t|  15.723         \t|\n",
      "|  [LightningModule]CDVAE.optimizer_step                                                                                                                                \t|  1.9769         \t|  400            \t|  790.75         \t|  15.713         \t|\n",
      "|  [LightningDataModule]CrystDataModule.setup                                                                                                                           \t|  278.61         \t|  2              \t|  557.22         \t|  11.073         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                       \t|  0.49862        \t|  804            \t|  400.89         \t|  7.9662         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                         \t|  0.93976        \t|  400            \t|  375.9          \t|  7.4697         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                              \t|  0.93259        \t|  400            \t|  373.03         \t|  7.4127         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.12327        \t|  100            \t|  12.327         \t|  0.24495        \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                           \t|  0.01266        \t|  804            \t|  10.179         \t|  0.20227        \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                           \t|  0.020445       \t|  400            \t|  8.178          \t|  0.16251        \t|\n",
      "|  [LightningModule]CDVAE.configure_gradient_clipping                                                                                                                   \t|  0.012598       \t|  400            \t|  5.039          \t|  0.10013        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                        \t|  0.02452        \t|  102            \t|  2.501          \t|  0.049698       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                         \t|  0.00453        \t|  400            \t|  1.812          \t|  0.036007       \t|\n",
      "|  [LightningModule]CDVAE.on_validation_model_zero_grad                                                                                                                 \t|  0.0095         \t|  100            \t|  0.95           \t|  0.018878       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                    \t|  0.00093905     \t|  804            \t|  0.755          \t|  0.015003       \t|\n",
      "|  [LightningModule]CDVAE.on_validation_model_eval                                                                                                                      \t|  0.0056863      \t|  102            \t|  0.58           \t|  0.011525       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                  \t|  0.00070398     \t|  804            \t|  0.566          \t|  0.011247       \t|\n",
      "|  [LightningModule]CDVAE.optimizer_zero_grad                                                                                                                           \t|  0.001135       \t|  400            \t|  0.454          \t|  0.0090215      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                       \t|  0.00036628     \t|  1204           \t|  0.441          \t|  0.0087632      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                          \t|  0.0041176      \t|  102            \t|  0.42           \t|  0.0083459      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                       \t|  0.00249        \t|  100            \t|  0.249          \t|  0.0049479      \t|\n",
      "|  [LightningModule]CDVAE.transfer_batch_to_device                                                                                                                      \t|  0.00019601     \t|  1204           \t|  0.236          \t|  0.0046896      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_start                                                                                                                   \t|  0.0004675      \t|  400            \t|  0.187          \t|  0.0037159      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.0855         \t|  2              \t|  0.171          \t|  0.003398       \t|\n",
      "|  [LightningModule]CDVAE.configure_optimizers                                                                                                                          \t|  0.0855         \t|  2              \t|  0.171          \t|  0.003398       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_end                                                                                     \t|  0.00125        \t|  100            \t|  0.125          \t|  0.0024839      \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                      \t|  0.055          \t|  2              \t|  0.11           \t|  0.0021858      \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                  \t|  0.0545         \t|  2              \t|  0.109          \t|  0.002166       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                         \t|  0.00077        \t|  100            \t|  0.077          \t|  0.0015301      \t|\n",
      "|  [LightningDataModule]CrystDataModule.val_dataloader                                                                                                                  \t|  0.024          \t|  2              \t|  0.048          \t|  0.00095382     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                             \t|  0.047          \t|  1              \t|  0.047          \t|  0.00093395     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  7.75e-05       \t|  400            \t|  0.031          \t|  0.00061601     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  1.99e-05       \t|  804            \t|  0.016          \t|  0.00031794     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                       \t|  0.00015686     \t|  102            \t|  0.016          \t|  0.00031794     \t|\n",
      "|  [Callback]LearningRateMonitor.on_after_backward                                                                                                                      \t|  4e-05          \t|  400            \t|  0.016          \t|  0.00031794     \t|\n",
      "|  [LightningModule]CDVAE.on_train_epoch_end                                                                                                                            \t|  0.00016        \t|  100            \t|  0.016          \t|  0.00031794     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                  \t|  0.00014706     \t|  102            \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  0.00014706     \t|  102            \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_zero_grad                                                                                                                    \t|  3.75e-05       \t|  400            \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                             \t|  3.75e-05       \t|  400            \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                      \t|  3.75e-05       \t|  400            \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [LightningModule]CDVAE.on_train_batch_end                                                                                                                            \t|  3.75e-05       \t|  400            \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  0.00068182     \t|  22             \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                               \t|  0.015          \t|  1              \t|  0.015          \t|  0.00029807     \t|\n",
      "|  [LightningModule]CDVAE.configure_callbacks                                                                                                                           \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CrystDataModule.prepare_data                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.prepare_data                                                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.setup                                                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.setup                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                         \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.setup                                                                                                                                         \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_start                                                                                                                           \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_start                                                                                           \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_fit_start                                                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_start                                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_start                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                         \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_start                                                                                                                    \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_start                                                                                    \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                           \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_validation_start                                                                                                                           \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                   \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_start                                                                                                              \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_start                                                                              \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                     \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_validation_epoch_start                                                                                                                     \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_before_batch_transfer                                                                                                                      \t|  0.0            \t|  1204           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_after_batch_transfer                                                                                                                       \t|  0.0            \t|  1204           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_start                                                                                                              \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_start                                                                              \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                     \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_validation_batch_start                                                                                                                     \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_end                                                                                                                \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_end                                                                                \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                       \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_validation_batch_end                                                                                                                       \t|  0.0            \t|  804            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_end                                                                                                                \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_end                                                                                \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                    \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_validation_epoch_end                                                                                                                       \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_end                                                                                                                      \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_end                                                                                      \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                             \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_validation_end                                                                                                                             \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                     \t|  0.0            \t|  102            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_end                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_end                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                        \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                           \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CrystDataModule.train_dataloader                                                                                                                \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_start                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_start                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_train_start                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_start                                                                                                                   \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_start                                                                                   \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                          \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_train_epoch_start                                                                                                                          \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_start                                                                                   \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                       \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                          \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_train_batch_start                                                                                                                          \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                  \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_zero_grad                                                                                    \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                        \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                           \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_before_zero_grad                                                                                                                           \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_backward                                                                                                                     \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_backward                                                                                     \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                         \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                            \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_before_backward                                                                                                                            \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_after_backward                                                                                      \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                          \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_after_backward                                                                                                                             \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_optimizer_step                                                                                                               \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_optimizer_step                                                                               \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                   \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_before_optimizer_step                                                                                                                      \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_end                                                                                                                     \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_end                                                                                     \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                            \t|  0.0            \t|  400            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_end                                                                                                                     \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                            \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CrystDataModule.state_dict                                                                                                                      \t|  0.0            \t|  22             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_save_checkpoint                                                                                                                     \t|  0.0            \t|  22             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_save_checkpoint                                                                                     \t|  0.0            \t|  22             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                         \t|  0.0            \t|  22             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                            \t|  0.0            \t|  22             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_save_checkpoint                                                                                                                            \t|  0.0            \t|  22             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.lr_scheduler_step                                                                                                                             \t|  0.0            \t|  100            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_end                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_end                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_train_end                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_end                                                                                                                             \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_end                                                                                             \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                 \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.on_fit_end                                                                                                                                    \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CrystDataModule.teardown                                                                                                                        \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]LearningRateMonitor.teardown                                                                                                                               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.teardown                                                                                               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                   \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]CDVAE.teardown                                                                                                                                      \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0a8f7f9e094b1abc3b12af12b1febe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/116 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datamodule.train_dataset = hydra.utils.instantiate(datamodule.datasets.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrystDataset(self.name='Formation energy train', self.path='C:/Users/TOSHIBA/Desktop/work/cdvae/data/perov_5/train.csv')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cdvae.pl_modules.model.CDVAE"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hydra.utils.log.info(\"Starting testing!\")\n",
    "trainer.test(datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import hydra\n",
    "\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "from hydra.experimental import compose\n",
    "from hydra import initialize_config_dir\n",
    "from pathlib import Path\n",
    "\n",
    "import smact\n",
    "from smact.screening import pauling_test\n",
    "\n",
    "from cdvae.common.constants import CompScalerMeans, CompScalerStds\n",
    "from cdvae.common.data_utils import StandardScaler, chemical_symbols\n",
    "from cdvae.pl_data.dataset import TensorCrystDataset\n",
    "from cdvae.pl_data.datamodule import worker_init_fn\n",
    "\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "CompScaler = StandardScaler(\n",
    "    means=np.array(CompScalerMeans),\n",
    "    stds=np.array(CompScalerStds),\n",
    "    replace_nan_token=0.)\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    if file_path[-3:] == 'npy':\n",
    "        data = np.load(file_path, allow_pickle=True).item()\n",
    "        for k, v in data.items():\n",
    "            if k == 'input_data_batch':\n",
    "                for k1, v1 in data[k].items():\n",
    "                    data[k][k1] = torch.from_numpy(v1)\n",
    "            else:\n",
    "                data[k] = torch.from_numpy(v).unsqueeze(0)\n",
    "    else:\n",
    "        data = torch.load(file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_model_path(eval_model_name):\n",
    "    import cdvae\n",
    "    model_path = (\n",
    "        Path(cdvae.__file__).parent / 'prop_models' / eval_model_name)\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def load_config(model_path):\n",
    "    with initialize_config_dir(str(model_path)):\n",
    "        cfg = compose(config_name='hparams')\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def load_model(model_path, load_data=False, testing=True):\n",
    "    with initialize_config_dir(str(model_path)):\n",
    "        cfg = compose(config_name='hparams')\n",
    "        model_cls = hydra.utils.get_class(cfg.model._target_)\n",
    "        \n",
    "        ckpts = list(model_path.glob('*.ckpt'))\n",
    "        if len(ckpts) > 0:\n",
    "            ckpt_epochs = np.array(\n",
    "                [int(ckpt.parts[-1].split('-')[0].split('=')[1]) for ckpt in ckpts])\n",
    "            ckpt = str(ckpts[ckpt_epochs.argsort()[-1]])\n",
    "        model = model_cls.load_from_checkpoint(ckpt)\n",
    "        model.lattice_scaler = torch.load(model_path / 'lattice_scaler.pt')\n",
    "        model.scaler = torch.load(model_path / 'prop_scaler.pt')\n",
    "\n",
    "        if load_data:\n",
    "            datamodule = hydra.utils.instantiate(\n",
    "                cfg.data.datamodule, _recursive_=False, scaler_path=model_path\n",
    "            )\n",
    "            if testing:\n",
    "                datamodule.setup('test')\n",
    "                test_loader = datamodule.test_dataloader()[0]\n",
    "            else:\n",
    "                datamodule.setup()\n",
    "                test_loader = datamodule.val_dataloader()[0]\n",
    "        else:\n",
    "            test_loader = None\n",
    "\n",
    "    return model, test_loader, cfg\n",
    "\n",
    "\n",
    "def get_crystals_list(\n",
    "        frac_coords, atom_types, lengths, angles, num_atoms):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        frac_coords: (num_atoms, 3)\n",
    "        atom_types: (num_atoms)\n",
    "        lengths: (num_crystals)\n",
    "        angles: (num_crystals)\n",
    "        num_atoms: (num_crystals)\n",
    "    \"\"\"\n",
    "    assert frac_coords.size(0) == atom_types.size(0) == num_atoms.sum()\n",
    "    assert lengths.size(0) == angles.size(0) == num_atoms.size(0)\n",
    "\n",
    "    start_idx = 0\n",
    "    crystal_array_list = []\n",
    "    for batch_idx, num_atom in enumerate(num_atoms.tolist()):\n",
    "        cur_frac_coords = frac_coords.narrow(0, start_idx, num_atom)\n",
    "        cur_atom_types = atom_types.narrow(0, start_idx, num_atom)\n",
    "        cur_lengths = lengths[batch_idx]\n",
    "        cur_angles = angles[batch_idx]\n",
    "\n",
    "        crystal_array_list.append({\n",
    "            'frac_coords': cur_frac_coords.detach().cpu().numpy(),\n",
    "            'atom_types': cur_atom_types.detach().cpu().numpy(),\n",
    "            'lengths': cur_lengths.detach().cpu().numpy(),\n",
    "            'angles': cur_angles.detach().cpu().numpy(),\n",
    "        })\n",
    "        start_idx = start_idx + num_atom\n",
    "    return crystal_array_list\n",
    "\n",
    "\n",
    "def smact_validity(comp, count,\n",
    "                   use_pauling_test=True,\n",
    "                   include_alloys=True):\n",
    "    elem_symbols = tuple([chemical_symbols[elem] for elem in comp])\n",
    "    space = smact.element_dictionary(elem_symbols)\n",
    "    smact_elems = [e[1] for e in space.items()]\n",
    "    electronegs = [e.pauling_eneg for e in smact_elems]\n",
    "    ox_combos = [e.oxidation_states for e in smact_elems]\n",
    "    if len(set(elem_symbols)) == 1:\n",
    "        return True\n",
    "    if include_alloys:\n",
    "        is_metal_list = [elem_s in smact.metals for elem_s in elem_symbols]\n",
    "        if all(is_metal_list):\n",
    "            return True\n",
    "\n",
    "    threshold = np.max(count)\n",
    "    compositions = []\n",
    "    for ox_states in itertools.product(*ox_combos):\n",
    "        stoichs = [(c,) for c in count]\n",
    "        # Test for charge balance\n",
    "        cn_e, cn_r = smact.neutral_ratios(\n",
    "            ox_states, stoichs=stoichs, threshold=threshold)\n",
    "        # Electronegativity test\n",
    "        if cn_e:\n",
    "            if use_pauling_test:\n",
    "                try:\n",
    "                    electroneg_OK = pauling_test(ox_states, electronegs)\n",
    "                except TypeError:\n",
    "                    # if no electronegativity data, assume it is okay\n",
    "                    electroneg_OK = True\n",
    "            else:\n",
    "                electroneg_OK = True\n",
    "            if electroneg_OK:\n",
    "                for ratio in cn_r:\n",
    "                    compositions.append(\n",
    "                        tuple([elem_symbols, ox_states, ratio]))\n",
    "    compositions = [(i[0], i[2]) for i in compositions]\n",
    "    compositions = list(set(compositions))\n",
    "    if len(compositions) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def structure_validity(crystal, cutoff=0.5):\n",
    "    dist_mat = crystal.distance_matrix\n",
    "    # Pad diagonal with a large number\n",
    "    dist_mat = dist_mat + np.diag(\n",
    "        np.ones(dist_mat.shape[0]) * (cutoff + 10.))\n",
    "    if dist_mat.min() < cutoff or crystal.volume < 0.1:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_fp_pdist(fp_array):\n",
    "    if isinstance(fp_array, list):\n",
    "        fp_array = np.array(fp_array)\n",
    "    fp_pdists = pdist(fp_array)\n",
    "    return fp_pdists.mean()\n",
    "\n",
    "\n",
    "def prop_model_eval(eval_model_name, crystal_array_list):\n",
    "\n",
    "    model_path = get_model_path(eval_model_name)\n",
    "\n",
    "    model, _, _ = load_model(model_path)\n",
    "    cfg = load_config(model_path)\n",
    "\n",
    "    dataset = TensorCrystDataset(\n",
    "        crystal_array_list, cfg.data.niggli, cfg.data.primitive,\n",
    "        cfg.data.graph_method, cfg.data.preprocess_workers,\n",
    "        cfg.data.lattice_scale_method)\n",
    "\n",
    "    dataset.scaler = model.scaler.copy()\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        shuffle=False,\n",
    "        batch_size=256,\n",
    "        num_workers=0,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "    for batch in loader:\n",
    "        preds = model(batch)\n",
    "        model.scaler.match_device(preds)\n",
    "        scaled_preds = model.scaler.inverse_transform(preds)\n",
    "        all_preds.append(scaled_preds.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds, axis=0).squeeze(1)\n",
    "    return all_preds.tolist()\n",
    "\n",
    "\n",
    "def filter_fps(struc_fps, comp_fps):\n",
    "    assert len(struc_fps) == len(comp_fps)\n",
    "\n",
    "    filtered_struc_fps, filtered_comp_fps = [], []\n",
    "\n",
    "    for struc_fp, comp_fp in zip(struc_fps, comp_fps):\n",
    "        if struc_fp is not None and comp_fp is not None:\n",
    "            filtered_struc_fps.append(struc_fp)\n",
    "            filtered_comp_fps.append(comp_fp)\n",
    "    return filtered_struc_fps, filtered_comp_fps\n",
    "\n",
    "\n",
    "def compute_cov(crys, gt_crys,\n",
    "                struc_cutoff, comp_cutoff, num_gen_crystals=None):\n",
    "    struc_fps = [c.struct_fp for c in crys]\n",
    "    comp_fps = [c.comp_fp for c in crys]\n",
    "    gt_struc_fps = [c.struct_fp for c in gt_crys]\n",
    "    gt_comp_fps = [c.comp_fp for c in gt_crys]\n",
    "\n",
    "    assert len(struc_fps) == len(comp_fps)\n",
    "    assert len(gt_struc_fps) == len(gt_comp_fps)\n",
    "\n",
    "    # Use number of crystal before filtering to compute COV\n",
    "    if num_gen_crystals is None:\n",
    "        num_gen_crystals = len(struc_fps)\n",
    "\n",
    "    struc_fps, comp_fps = filter_fps(struc_fps, comp_fps)\n",
    "\n",
    "    comp_fps = CompScaler.transform(comp_fps)\n",
    "    gt_comp_fps = CompScaler.transform(gt_comp_fps)\n",
    "\n",
    "    struc_fps = np.array(struc_fps)\n",
    "    gt_struc_fps = np.array(gt_struc_fps)\n",
    "    comp_fps = np.array(comp_fps)\n",
    "    gt_comp_fps = np.array(gt_comp_fps)\n",
    "\n",
    "    struc_pdist = cdist(struc_fps, gt_struc_fps)\n",
    "    comp_pdist = cdist(comp_fps, gt_comp_fps)\n",
    "\n",
    "    struc_recall_dist = struc_pdist.min(axis=0)\n",
    "    struc_precision_dist = struc_pdist.min(axis=1)\n",
    "    comp_recall_dist = comp_pdist.min(axis=0)\n",
    "    comp_precision_dist = comp_pdist.min(axis=1)\n",
    "\n",
    "    cov_recall = np.mean(np.logical_and(\n",
    "        struc_recall_dist <= struc_cutoff,\n",
    "        comp_recall_dist <= comp_cutoff))\n",
    "    cov_precision = np.sum(np.logical_and(\n",
    "        struc_precision_dist <= struc_cutoff,\n",
    "        comp_precision_dist <= comp_cutoff)) / num_gen_crystals\n",
    "\n",
    "    metrics_dict = {\n",
    "        'cov_recall': cov_recall,\n",
    "        'cov_precision': cov_precision,\n",
    "        'amsd_recall': np.mean(struc_recall_dist),\n",
    "        'amsd_precision': np.mean(struc_precision_dist),\n",
    "        'amcd_recall': np.mean(comp_recall_dist),\n",
    "        'amcd_precision': np.mean(comp_precision_dist),\n",
    "    }\n",
    "\n",
    "    combined_dist_dict = {\n",
    "        'struc_recall_dist': struc_recall_dist.tolist(),\n",
    "        'struc_precision_dist': struc_precision_dist.tolist(),\n",
    "        'comp_recall_dist': comp_recall_dist.tolist(),\n",
    "        'comp_precision_dist': comp_precision_dist.tolist(),\n",
    "    }\n",
    "\n",
    "    return metrics_dict, combined_dist_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(10)[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = torch.load(r'C:\\Users\\TOSHIBA\\Desktop\\work\\hydra\\singlerun\\2024-03-28\\test\\eval_gen.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['eval_setting', 'frac_coords', 'num_atoms', 'atom_types', 'lengths', 'angles', 'all_frac_coords_stack', 'all_atom_types_stack', 'time'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen['all_atom_types_stack']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
